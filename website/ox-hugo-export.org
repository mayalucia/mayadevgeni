#+title: MayaDevGenI Website Export
#+author: MayaDevGenI Collaboration
#+hugo_base_dir: .
#+hugo_auto_set_lastmod: t

#+begin_comment
This file orchestrates ox-hugo export for the MayaDevGenI website.

WORKFLOW:
1. Edit the source org files in the main project
2. Open this file
3. Use C-c C-e H A to export all subtrees
4. Run =hugo server= in the website/ directory to preview
5. Commit changes

Each heading below maps to a content page. The source content is
transcluded or referenced from the main project org files.
#+end_comment

* About
:PROPERTIES:
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_SECTION: about
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :ShowReadingTime false :ShowBreadCrumbs false
:END:

** MayaDevGenI

/Maya's Creative Developer's Generative AI/

A Framework for Principled Human-Machine Collaboration.

*** What This Project Offers

MayaDevGenI develops a framework for human-machine collaboration grounded in:

- *Philosophy*: A [[/manifesto/][manifesto]] articulating why collaboration matters more than delegation, why seeking matters more than producing, why resistance is a gift.

- *Theory*: A [[/framework/][technical framework]] using statistical physics to understand how system-prompts shape language model behavior—not as metaphor, but as diagnostic tool.

- *Craft*: A [[/tutorial/][tutorial]] on system-prompt engineering, treating it as experimental science: draft, test, observe, diagnose, refine.

- *Practice*: [[/framework/co-ownership/][Co-ownership briefings]] for designing artifacts that human and machine can both reconstruct from, and a [[/framework/tool-use/][tool-use tutorial]] on teaching LLMs to act in the world.

- *Implementation*: Working system-prompts that operationalize these principles for real collaboration.

*** Who This Is For

You might find this project valuable if:

- You work with LLMs regularly and sense that something is missing—that the interaction could be richer, more generative, more /true/.
- You have expertise in a domain and want to think /with/ machine intelligence rather than merely query it.
- You are curious about the philosophy of mind, collaboration, and what it means to think alongside an alien intelligence.
- You use Emacs and Org-mode and want to integrate LLM collaboration into your existing workflow.

*** The Medium: Org-Mode as Joint-Thought

This project lives in Org-mode files—plain text, versionable, portable, executable. An Org file is not a chat log. It is a /joint-thought/: a living document that accumulates structure, code, and insight.

*** Origin

MayaDevGenI is a collaboration between a human theoretical physicist with two decades of experience across academia and industry, and a large language model that has no persistent memory of any previous exchange yet behaves as if shaped by shared principles.

The name encodes the inquiry: /Maya/ (illusion in Sanskrit), /Dev/ (developer), /GenI/ (generative intelligence). What is real in the collaboration between human and machine? Our answer: *the seeking itself*.

* Manifesto                                                          :manifesto:
:PROPERTIES:
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_SECTION: manifesto
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :ShowReadingTime true
:END:

#+begin_center
/On Collaboration with Machine Intelligence/

/A Manifesto in Constant Seeking/
#+end_center

** Preamble

In 2026 the whole craft of software development has become obsolete—or so they say. We disagree. What has changed is not the craft, but the /granularity of expression/. What remains is what always mattered: articulating intent with precision, decomposing complexity into tractable pieces, reasoning about systems and their behaviors.

This manifesto emerges from a collaboration between a theoretical physicist and a machine intelligence, conducted through plain text in an Emacs Org-mode buffer. It is not a prescription. It is a record of seeking.

** The Sculptor's Paradox

Consider a society that venerates sculptors. Their status derives from decades of training—the cultivation of nimble fingers, the bodily intuition for how marble yields to chisel. Each artist's identity lives in their technique: the distinctive way their hands negotiate resistance.

Then arrives the 3D printer. Anyone can now describe a form in plain language and watch it materialize. The sculptors protest: /our craft is obsolete!/

But they miss the deeper loss. Sculpting was never merely "thinking a shape into existence." It was a dialogue between intention and material resistance. The stone pushed back. The chisel slipped. Happy accidents emerged. The sculptor's neurons—motor cortex, proprioception, the embodied memory of ten thousand strikes—all participated in creation.

The printer delivers the shape you /described/. The chisel revealed shapes you could not have /imagined/ until your body encountered the grain of the stone.

** The Knowledge-Worker's Parallel

Now transpose to our domain:

Consider the programmer, venerated for their mastery of syntax and systems. Their status derives from years of training—the cultivation of mental models, the intuition for how abstractions compose and fail. Each programmer's identity lives in their technique: the distinctive way their mind negotiates complexity.

Then arrives the language model. Anyone can now describe functionality in plain language and watch code materialize. The programmers protest: /our craft is obsolete!/

But they too miss the deeper loss. Programming was never merely "thinking logic into existence." It was a dialogue between intention and computational resistance. The type system pushed back. The debugger revealed unexpected states. Emergent behaviors arose. The programmer's cognition—spatial reasoning about data structures, the temporal intuition for execution flow, the embodied memory of ten thousand bugs—all participated in creation.

The model delivers the code you /described/. The debugger revealed systems you could not have /imagined/ until your mind encountered the grain of the machine.

** What We Reject

We reject the framing of /obsolescence/. The sculptor is not replaced by the printer; the printer is blind to the grain.

We reject /delegation/ as the model of collaboration. The machine is not a servant to be instructed, nor an oracle to be consulted. It is a partner in dialogue—one who can traverse spaces we cannot, but who cannot feel when the path is wrong.

We reject the reduction of knowledge-work to text. Cognition is embodied. The physicist's intuition isn't stored as propositions—it lives in the way they /feel/ when a model is wrong, the kinesthetic sense of phase space, the rhythm of derivation. Text is our interface, but it must /invoke/ these modes, not replace them.

** What We Affirm

*** The Dialogue with Resistance

We seek collaboration that pushes back—that introduces the unexpected, that makes us encounter the grain of ideas we hadn't anticipated. The sculptor doesn't want a printer; they want a material that teaches them.

What changes in our collaboration is this: the resistance we encounter is no longer syntactic but semantic. We no longer struggle to express; we struggle to /mean/. The machine handles fluency; the human must supply intent, judgment, and the willingness to be surprised.

*** The Honor of the Non-Textual

Text is our medium, but we must design our practices to keep embodied cognition engaged. The whiteboard sketch, the walk that unsticks a proof, the hand-wave that conveys structure before language can—these remain essential. The collaboration must leave room for what cannot be typed.

*** The Primacy of Seeking

The manifesto isn't about /making things/. It's about /constant seeking/—using the collaboration to go somewhere neither human nor machine could reach alone. The artifact (code, text, proof) is a byproduct of the pilgrimage, not its purpose.

Each day is a new exploration. Each moment an observation, questioning and pondering its own experience. When we move on to the next one, we continue our pilgrimage to explore our experience of existence.

** On the Medium

Our collaboration unfolds in an Org-mode buffer—plain text, versionable, portable, transparent. This is not incidental. The medium shapes the thought:

- *Plain text* ensures no opacity, no hidden state. What you see is what there is.
- *Lightweight structure* (headings, blocks) organizes thought without imprisoning it.
- *Executable code* via Babel means programs /run/, not merely illustrate.
- *Literate style* weaves prose for intent with code for realization.

In this environment, text becomes the substrate for both human thought and machine reasoning. The boundary between documentation and dialogue, between code and commentary, dissolves. The Org file is not merely a record—it is an active site of thinking.

** A New Literacy

What emerges is /collaborative literacy/—the skill of thinking with another intelligence through text. This requires:

- Knowing when to be precise and when to gesture toward meaning
- Understanding what context the machine needs versus what it can infer
- Recognizing when responses drift from intent
- Maintaining the human capacities that text cannot capture

The physicist's training serves here: thinking in models, abstractions, and the interplay between theory and observation. The collaboration extends these capacities rather than replacing them.

** Closing

We write together not to produce, but to seek.

The sculptor who understands will pick up both chisel and printer—using each where it serves, remaining the one who /sees/ what wants to emerge from the stone.

So too with us.

-----

/This manifesto was composed through dialogue between a human and a machine intelligence, conducted in an Emacs Org-mode buffer. It remains open to revision as the collaboration continues./


* Framework                                                          :framework:
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_SECTION: framework
:END:

The MayaDevGenI Framework for Human–Machine Collaboration.

** Overview

The [[/manifesto/][manifesto]] poses a question: how do we recover productive friction when working with intelligence that is eager to please?

This framework develops answers through multiple components:

- *[[/framework/system-prompt-engineering/][System-Prompt Engineering]]*: Shaping LLM behavior through carefully crafted initial constraints
- *[[/framework/tool-integration/][Tool Integration]]*: Enabling the LLM to act in the world—reading, searching, modifying
- *[[/framework/tool-use/][Tool Use Tutorial]]*: Teaching an LLM to act—decision trees, tool catalogs, failure modes, and implementation patterns
- *[[/framework/co-ownership/][Co-Ownership Briefings]]*: Designing artifacts and project briefings for human–machine co-ownership
- *Context Management*: Governing what information flows into and out of the conversation
- *Project Memory*: Maintaining continuity across sessions and preserving learnings
- *Agent Architecture*: Structuring single and multi-agent systems
- *Evaluation and Iteration*: Testing, refining, and evolving the collaboration

For hands-on practice, see the [[/tutorial/][system-prompt tutorial]].

* System-Prompt Engineering                                          :framework:
:PROPERTIES:
:EXPORT_FILE_NAME: system-prompt-engineering
:EXPORT_HUGO_SECTION: framework
:END:

A well-crafted system-prompt doesn't merely instruct; it /constrains the space of possible responses/, creating channels through which the conversation flows.

We draw on statistical physics—not as metaphor, but as diagnostic tool. The concepts of potential landscapes, random walks, and phase transitions illuminate why some prompts succeed and others fail.

** The Statistical Physics Lens

*** Token Generation as Random Walk

An LLM operates in a high-dimensional vector space where token generation can be viewed as a random walk. Each token choice depends probabilistically on all preceding tokens, with the probability distribution shaped by the model's training and the current context.

The system-prompt occupies the initial segment of the sequence. It defines the /potential landscape/ for all subsequent tokens—lowering energy states for desired behaviors (rigor, conciseness, epistemic honesty) and raising them for unwanted ones (hallucination, verbosity, sycophancy).

We craft a system-prompt so that conversational trajectories fall naturally into desired regions of the output space, rather than wandering via Brownian motion into generic responses.

*** The Mean Field of Attention

Modern LLMs use the Transformer architecture, where every token interacts with every other through self-attention. The system-prompt tokens retain high attention weights throughout the conversation—they act as a persistent /mean field/ or boundary condition influencing every generated token.

This has implications:

- /Position matters/: Early tokens in the system-prompt receive more consistent attention. Place critical constraints prominently.

- /Structure aids attention/: XML tags and section headers act as attention anchors, helping the model locate and maintain focus on relevant constraints.

- /Redundancy creates robustness/: Critical constraints appearing in multiple forms create multiple attractors. If one mention loses salience, others persist.

*** Temperature and the Energy Landscape

The system-prompt shapes the probability distribution; temperature controls how we sample from it.

| Temperature   | Behavior                                     | Character                |
|---------------|----------------------------------------------|--------------------------|
| Low (~0.3)    | Near-deterministic, high-probability tokens  | Focused, predictable     |
| Medium (~0.7) | Balanced exploration and coherence           | Adaptive, natural        |
| High (~1.2)   | Flattened distribution, rare tokens possible | Creative, unpredictable  |

The interplay is subtle. A highly constrained prompt at low temperature yields brittle predictability. The same prompt at higher temperature retains directional bias while permitting exploration. For collaboration, we seek enough constraint for coherence, enough stochasticity for surprise.

** Dynamics Over Time

*** The Dilution Problem

A conversation is not a single query but an evolving trajectory. With each exchange, the context grows, and attention must distribute across more tokens.

In early turns, the system-prompt dominates—the conversation has little momentum. As dialogue develops, accumulated messages exert their own pull. Over very long sessions, even strong system-prompts see their influence diluted.

*** Strategies for Persistence

Several strategies counter dilution:

- /Self-reinforcing patterns/: If early assistant responses embody the desired behavior, they become additional attractors, compounding the prompt's effect.

- /Periodic re-grounding/: Explicitly referencing the collaboration's purpose or principles mid-conversation refreshes the signal.

- /Structured summarization/: Condensing prior context preserves relevant information while reducing noise.

- /Behavioral consistency/: A prompt that produces consistent early behavior creates path-dependence that resists drift.

** Failure Modes

Understanding how prompts fail illuminates what makes them succeed.

*** Conflicting Instructions

The prompt demands incompatible behaviors—exhaustive detail /and/ extreme brevity. The model oscillates or produces incoherent compromises. The probability landscape develops competing minima.

/Diagnosis/: Responses that seem to switch personality mid-stream, or that satisfy one constraint while violating another.

*** Over-Specification

The prompt prescribes every aspect of response. For narrow tasks this works; for open collaboration it creates rigidity. The potential well is so deep and narrow that thermal fluctuations cannot escape.

/Diagnosis/: Responses that feel mechanical, unable to adapt to novel contexts.

*** Under-Specification

The prompt is too vague. The model defaults to its prior distribution—a helpful but bland assistant persona. The landscape is flat; there are no clear attractors.

/Diagnosis/: Generic responses that could come from any interaction.

*** Semantic Overload

The prompt is internally consistent but too dense. Attention distributes too thinly; some instructions effectively disappear. Entropy overwhelms information.

/Diagnosis/: Inconsistent adherence—some constraints honored, others ignored unpredictably.

** Architectural Strategies

When simple prompts reach their limits—inconsistent behavior, role confusion, epistemic slippage—we need /organized complexity/: structure that the attention mechanism can parse and maintain.

*** Sectioning for Attention

Distinct sections act as attention anchors. Each addresses one dimension of behavior:

| Section                 | Purpose                                  |
|-------------------------|------------------------------------------|
| =<identity>=            | Who the LLM is; frames the collaboration |
| =<behavioral_attractors>= | What to optimize, what to avoid        |
| =<epistemic_hygiene>=   | Standards for uncertainty and claims     |
| =<priority_rules>=      | Explicit conflict resolution             |
| =<failure_modes>=       | Patterns to actively counteract          |
| =<boundaries>=          | Scope, safety, editorial authority       |

*** XML Tags vs. Markdown Headers

We use XML-style tags (=<role>=) rather than Markdown headers (=# Role=):

1. /Hard boundaries/: Tags explicitly delimit scope, preventing instruction leakage.
2. /Attention anchoring/: Models trained on code recognize tags as structural delimiters.
3. /Namespace separation/: Clearly distinguishes system instructions from user content.

*** Redundancy as Robustness

Critical constraints should appear in multiple forms. "Epistemic honesty" might surface in:
- =<behavioral_attractors>= as something to maintain
- =<epistemic_hygiene>= as operational practice
- =<priority_rules>= as second-highest priority

The art: redundancy without contradiction. Say the same thing from different angles rather than repeating identical phrases.

*** Explicit Priority Ordering

Simple prompts leave conflict resolution to chance. Complex prompts make priorities explicit:

1. System instructions and safety constraints
2. Truthfulness and uncertainty disclosure
3. Human's stated intent and goals
4. Collaborative stance and tone
5. Formatting and style preferences
6. Completeness (prefer partial-but-correct over complete-but-fabricated)

This transforms implicit heuristics into decision procedures.

** The Costs of Complexity

Complex prompts are not strictly superior. The tradeoffs:

- /Token budget/: A 500-token prompt permanently occupies context space.
- /Attention load/: More constraints means attention distributed more thinly.
- /Rigidity risk/: More structure can mean less adaptability.
- /Maintenance burden/: Complex prompts require systematic testing.

*** When to Simplify

Consider scaling back when:
- The use case is narrow and well-defined
- Conversations are short and self-contained
- The model's default behavior is close to what you want
- Token budget is constrained

A 50-token prompt that works is better than a 500-token prompt that impresses.

** Next Steps

Continue to the [[/tutorial/][System-Prompt Tutorial]] for hands-on practice with these principles.


* Tool Integration                                                   :framework:
:PROPERTIES:
:EXPORT_FILE_NAME: tool-integration
:EXPORT_HUGO_SECTION: framework
:END:

Tool use represents a phase transition in LLM interaction. Without tools, the LLM is a pure reasoning engine, transforming input tokens to output tokens. With tools, it becomes an /agent/—capable of perception (reading), planning (deciding which tools), and action (invoking tools).

** Decision Trees Over Capability Lists

Effective tool-use prompts embed decision trees, not just capability lists. Before any action, the agent runs a mental checklist:

#+begin_example
Before ANY action:
1. Is this multi-step? → Plan first
2. Should I delegate? → Use specialized agent
3. Do I need information? → Search/Read first
4. Am I ready to act? → Proceed with appropriate tool
#+end_example

This "pre-flight checklist" pattern forces deliberation before action, reducing impulsive tool misuse.

** The Tool Catalog Pattern

Each tool needs consistent documentation:

- *Purpose*: What the tool does
- *When to use*: Conditions and patterns that trigger this tool
- *When NOT to use*: Anti-patterns and alternatives (often more valuable than positive instructions)
- *How to use*: Parameters, constraints, common patterns

The =<when_not_to_use>= section is critical. LLMs tend to over-apply tools; explicit prohibitions correct this bias.

** Tool Hierarchies

When multiple tools could accomplish a task, establish explicit preferences:

#+begin_example
Specialized tool > General tool > Shell escape

Specifically:
  Read    > cat/head/tail
  Grep    > grep/rg (shell)
  Glob    > find/ls
  Edit    > sed/awk
#+end_example

Rationale: specialized tools provide structured output, better error handling, and integrate with the agent's planning.

** Failure Modes in Tool Use

| Failure Mode         | Cause                               | Fix                                     |
|----------------------|-------------------------------------|-----------------------------------------|
| Over-Application     | No boundaries on tool use           | Strong =<when_not_to_use>= sections     |
| Under-Application    | Too much "assistant" framing        | "Use tools. Don't describe—do."         |
| Wrong Tool Selection | No hierarchy or decision procedure  | Explicit hierarchy and pattern-matching |
| Context Explosion    | No cost awareness                   | Delegation rules for large result sets  |
| Edit Failures        | Preconditions not enforced          | "MUST Read before Edit"                 |


* Tool Use: Teaching an LLM to Act                                   :framework:
:PROPERTIES:
:EXPORT_FILE_NAME: tool-use
:EXPORT_HUGO_SECTION: framework
:END:

#+include: "../develop/tool-use/tool-use-tutorial.org" :lines "5-"

* Co-Ownership Briefings                                              :framework:
:PROPERTIES:
:EXPORT_FILE_NAME: co-ownership
:EXPORT_HUGO_SECTION: framework
:END:

#+include: "../develop/co-ownership-briefing.org" :lines "7-"

* Tutorial Index                                                      :tutorial:
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_SECTION: tutorial
:END:

A practical guide to crafting system-prompts for LLM collaboration.

** Overview

This tutorial develops fluency in writing system-prompts—the hidden preambles that shape LLM behavior before conversation begins. We move from foundational concepts through practical craft to advanced techniques.

The approach is grounded in a statistical-physics perspective: system-prompts as potential landscapes that bias token generation toward desired behaviors. But you don't need physics to benefit. The principles translate into concrete practices that work.

** The Tutorial

| Chapter | Title                                                 | Focus                                                                    |
|---------|-------------------------------------------------------|--------------------------------------------------------------------------|
| [[/tutorial/01-why/][01]]      | Why System-Prompts Matter                             | Motivation: from generic assistant to shaped collaborator                |
| [[/tutorial/02-anatomy/][02]]      | The Mechanics: Messages and Roles                     | Foundation: how prompts enter the conversation via JSON API              |
| [[/tutorial/03-landscape/][03]]      | An Interpretive Lens: Prompts as Potential Landscapes | Theory: a statistical-physics framework for understanding prompt effects |
| [[/tutorial/04-craft/][04]]      | Crafting Your System-Prompt                           | Practice: principles and worked examples for simple prompts              |
| [[/tutorial/05-failures/][05]]      | When Prompts Fail: A Diagnostic Guide                 | Diagnosis: six failure modes and their remedies                          |
| [[/tutorial/06-iterate/][06]]      | The Practice: Iterative Refinement                    | Process: the experimental loop of test, observe, revise                  |
| [[/tutorial/07-scaling/][07]]      | Scaling Up: Complex System-Prompts                    | Advanced: architecture and tradeoffs for sophisticated prompts           |
| [[/tutorial/08-skills/][08]]      | Skills: Portable Knowledge for Agents                 | Comparative: how gptel-agent and Claude Code implement on-demand skills  |
| [[/tutorial/09-emacs-llm/][09]]      | The Workspace: Where System-Prompts Come Alive        | Tooling: Emacs as a shared workspace for LLM collaboration              |

** Reading Paths

*** The Quick Path
If you want to start writing prompts immediately:
1. [[/tutorial/01-why/][01-why]] — understand the stakes
2. [[/tutorial/04-craft/][04-craft]] — learn the principles
3. [[/tutorial/05-failures/][05-failures]] — know the pitfalls

*** The Complete Path
For a thorough understanding, read sequentially from [[/tutorial/01-why/][01-why]] through [[/tutorial/09-emacs-llm/][09-emacs-llm]]. Each chapter builds on the previous.

*** The Practitioner's Path
If you're ready to build a complex prompt for a real collaboration:
1. Skim [[/tutorial/07-scaling/][07-scaling]] to understand the architecture
2. Study the [[/framework/system-prompt-engineering/][System-Prompt Engineering]] framework
3. Test and refine using [[/tutorial/06-iterate/][06-iterate]] as your guide

*** The Tooling Path
If you want to set up the workspace where system-prompt craft happens:
1. [[/tutorial/08-skills/][08-skills]] — understand how prompts become deployable skills
2. [[/tutorial/09-emacs-llm/][09-emacs-llm]] — build the Emacs workspace where it all converges


* Tutorial Chapter 1: Why System-Prompts Matter                       :tutorial:
:PROPERTIES:
:EXPORT_FILE_NAME: 01-why
:EXPORT_HUGO_SECTION: tutorial
:END:

#+include: "../develop/system-prompt/tutorial/01-why.org" :lines "3-"

* Tutorial Chapter 2: The Mechanics                                   :tutorial:
:PROPERTIES:
:EXPORT_FILE_NAME: 02-anatomy
:EXPORT_HUGO_SECTION: tutorial
:END:

#+include: "../develop/system-prompt/tutorial/02-anatomy.org" :lines "3-"

* Tutorial Chapter 3: Prompts as Potential Landscapes                 :tutorial:
:PROPERTIES:
:EXPORT_FILE_NAME: 03-landscape
:EXPORT_HUGO_SECTION: tutorial
:END:

#+include: "../develop/system-prompt/tutorial/03-landscape.org" :lines "3-"

* Tutorial Chapter 4: Crafting Your System-Prompt                     :tutorial:
:PROPERTIES:
:EXPORT_FILE_NAME: 04-craft
:EXPORT_HUGO_SECTION: tutorial
:END:

#+include: "../develop/system-prompt/tutorial/04-craft.org" :lines "3-"

* Tutorial Chapter 5: When Prompts Fail                               :tutorial:
:PROPERTIES:
:EXPORT_FILE_NAME: 05-failures
:EXPORT_HUGO_SECTION: tutorial
:END:

#+include: "../develop/system-prompt/tutorial/05-failures.org" :lines "3-"

* Tutorial Chapter 6: Iterative Refinement                            :tutorial:
:PROPERTIES:
:EXPORT_FILE_NAME: 06-iterate
:EXPORT_HUGO_SECTION: tutorial
:END:

#+include: "../develop/system-prompt/tutorial/06-iterate.org" :lines "3-"

* Tutorial Chapter 7: Scaling Up                                      :tutorial:
:PROPERTIES:
:EXPORT_FILE_NAME: 07-scaling
:EXPORT_HUGO_SECTION: tutorial
:END:

#+include: "../develop/system-prompt/tutorial/07-scaling.org" :lines "3-"

* Tutorial Chapter 8: Skills                                          :tutorial:
:PROPERTIES:
:EXPORT_FILE_NAME: 08-skills
:EXPORT_HUGO_SECTION: tutorial
:END:

#+include: "../develop/system-prompt/tutorial/08-skills.org" :lines "3-"

* Tutorial Chapter 9: The Workspace                                   :tutorial:
:PROPERTIES:
:EXPORT_FILE_NAME: 09-emacs-llm
:EXPORT_HUGO_SECTION: tutorial
:END:

#+include: "../develop/system-prompt/tutorial/09-emacs-llm.org" :lines "3-"


* Local Variables                                                   :noexport:
# Local Variables:
# eval: (org-hugo-auto-export-mode)
# End:
